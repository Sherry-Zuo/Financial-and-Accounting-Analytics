{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assign3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLPmqLjecn6u",
        "colab_type": "text"
      },
      "source": [
        "# **BA 870 – Assignment 3**\n",
        "\n",
        "**Shangkun(Sherry) Zuo, Yuqi(Yoki) Liu, Yanni Lan, Jiayuan Zou, Ziyan Pei, Siqi Zhang**  \n",
        "Cohort B  \n",
        "April 6, 2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEtsGBGqiNEJ",
        "colab_type": "text"
      },
      "source": [
        "##Upload data to Pandas Dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oykHvkf6cgoZ",
        "colab_type": "code",
        "outputId": "393bd003-9bc9-4c43-99e7-24b4371e5046",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-82539ce3-0014-4584-9048-3e9af6c10772\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-82539ce3-0014-4584-9048-3e9af6c10772\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving assign3.csv to assign3.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7za5nJ2PHc8o",
        "colab_type": "text"
      },
      "source": [
        "The textfile with the labelled training and testing data of\n",
        "Reuters News Articles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hIoRRa9iR3g",
        "colab_type": "code",
        "outputId": "fcf9778d-76c1-484c-d2ef-38b2f06b7a20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv('assign3.csv')\n",
        "pd.DataFrame.from_records(df)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TEST</th>\n",
              "      <th>EARNINGS</th>\n",
              "      <th>ACQUIS</th>\n",
              "      <th>NEWS_TEXT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Mounting trade friction between the U.S. And J...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>survey of provinces and seven cities showed v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Shr .p .p  Div .p .p making .p .p  Turnover . ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Whim Creek Consolidated NL&gt; said the consortiu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>The number of workers employed in the West Ger...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   TEST  EARNINGS  ACQUIS                                          NEWS_TEXT\n",
              "0     1         0       0  Mounting trade friction between the U.S. And J...\n",
              "1     1         0       0   survey of provinces and seven cities showed v...\n",
              "2     1         1       0  Shr .p .p  Div .p .p making .p .p  Turnover . ...\n",
              "3     1         0       1  Whim Creek Consolidated NL> said the consortiu...\n",
              "4     1         0       0  The number of workers employed in the West Ger..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lG7U0ihkKJIB",
        "colab_type": "text"
      },
      "source": [
        "## Dataset Overview"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxgPoXXSI0aS",
        "colab_type": "code",
        "outputId": "5fa06cd5-b337-4669-aeaf-b78010d60c52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#dimension check\n",
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2165, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOiOvu9RI5Gf",
        "colab_type": "text"
      },
      "source": [
        "This is a subset of the Reuters-21578 dataset with\n",
        "2,165 observations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBjqcyo-JtqI",
        "colab_type": "text"
      },
      "source": [
        "##### Columns' Descriptions:  \n",
        "\n",
        "**TEST** = a variable that equals “1” if the observation will be part of the Testing set to evaluate your trained machine learning model, otherwise it is equal to “0” which means it will be used for the Training sample for the model.  \n",
        "**EARNINGS** = a variable that equals “1” if the text data is labelled as an “Earnings Announcement” news; otherwise it is equal to “0”  \n",
        "**ACQUIS** = a variable that equals “1” if the text data is labelled as an “Corporate Acquisition” news items on Reuters; otherwise it is equal to “0”  \n",
        "**NEWS_TEXT** = a string of text that captures the beginning of the actual news report on\n",
        "Reuters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEhyili6O8Yp",
        "colab_type": "code",
        "outputId": "9316fac2-264f-4c6f-c345-533234667bae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#check missing values\n",
        "df.isna().any()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TEST         False\n",
              "EARNINGS     False\n",
              "ACQUIS       False\n",
              "NEWS_TEXT    False\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcOfLH4xPK_i",
        "colab_type": "text"
      },
      "source": [
        "The dataset is cleaning, and ready to go next step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhumGUZuPRJn",
        "colab_type": "code",
        "outputId": "933b50e5-8779-494c-852c-2bda2ae929eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "#summary of statistics, check outliers\n",
        "df.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TEST</th>\n",
              "      <th>EARNINGS</th>\n",
              "      <th>ACQUIS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2165.000000</td>\n",
              "      <td>2165.000000</td>\n",
              "      <td>2165.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.263741</td>\n",
              "      <td>0.145497</td>\n",
              "      <td>0.373210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.440762</td>\n",
              "      <td>0.352682</td>\n",
              "      <td>0.483769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              TEST     EARNINGS       ACQUIS\n",
              "count  2165.000000  2165.000000  2165.000000\n",
              "mean      0.263741     0.145497     0.373210\n",
              "std       0.440762     0.352682     0.483769\n",
              "min       0.000000     0.000000     0.000000\n",
              "25%       0.000000     0.000000     0.000000\n",
              "50%       0.000000     0.000000     0.000000\n",
              "75%       1.000000     0.000000     1.000000\n",
              "max       1.000000     1.000000     1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EjiorhUQD-O",
        "colab_type": "text"
      },
      "source": [
        "The dataset does not have obvious outliers, so it's ready to go next step\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4CmWYQhTtAP",
        "colab_type": "text"
      },
      "source": [
        "##### Numeric Variables' Value Count Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSexJBtBQ4m1",
        "colab_type": "code",
        "outputId": "1d96ff94-cb33-4d02-be75-dd23d107048c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df['TEST'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1594\n",
              "1     571\n",
              "Name: TEST, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJX3V_2XR7q6",
        "colab_type": "text"
      },
      "source": [
        "There are 1594 observations in the training set, and 571 observations in the testing set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOB9UbyiRPuB",
        "colab_type": "code",
        "outputId": "39a7c3f4-d098-4801-f5b6-65787a7d5bd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df['EARNINGS'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1850\n",
              "1     315\n",
              "Name: EARNINGS, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcOGD-vZSR4i",
        "colab_type": "text"
      },
      "source": [
        "There are 315 news are labeled \"Earnings Announcement\", and 1850 news are not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEBdz4BQRTdj",
        "colab_type": "code",
        "outputId": "45886835-eb9b-4d96-a8d7-b43b5c16e9b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df['ACQUIS'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1357\n",
              "1     808\n",
              "Name: ACQUIS, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-3m3xbiSaPo",
        "colab_type": "text"
      },
      "source": [
        "There are 808 news are labeled “Corporate Acquisition”, and 1357 news are not. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tT68K6z4sXLX",
        "colab_type": "text"
      },
      "source": [
        "# DistilBERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMcq-bGdV2AV",
        "colab_type": "text"
      },
      "source": [
        "## Install the transformers library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvhJDq85WN2g",
        "colab_type": "code",
        "outputId": "bc145325-0926-4456-faec-3da1d53b94d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "#installing the huggingface transformers library so we can load our deep learning NLP model\n",
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/ba/dda44bbf35b071441635708a3dd568a5ca6bf29f77389f7c7c6818ae9498/transformers-2.7.0-py3-none-any.whl (544kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 6.8MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 53.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 53.1MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 39.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.33)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.33 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.33)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.33->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.33->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=ed26bcba3235705b0e9f900c5a19033111bcbddbf63b8d68a9c06e913ae48ae6\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kvzJBI6V7g2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import torch\n",
        "import transformers as ppb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOlV3iFzUohX",
        "colab_type": "text"
      },
      "source": [
        "## Load the pre-trained DistilBERT model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cplP95HUtKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For DistilBERT:\n",
        "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dklELbMQU89a",
        "colab_type": "text"
      },
      "source": [
        "Right now, the variable `model` holds a pretrained distilBERT model -- a version of BERT that is smaller, but much faster and requiring less memory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogK-MOMkpMC5",
        "colab_type": "text"
      },
      "source": [
        "## Prepare Model #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMe7ZlAnpRBE",
        "colab_type": "text"
      },
      "source": [
        "Before we can hand our sentences to BERT, we need to do some minimal processing to put our dataset in the format that BERT requirement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhU3C8a1pcLp",
        "colab_type": "text"
      },
      "source": [
        "### Prepare the Reuters News dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VuzloGvpzXt",
        "colab_type": "text"
      },
      "source": [
        "##### Tokenization  \n",
        "Our first step is to tokenize the sentences -- break them up into word and subwords in the format BERT is comfortable with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5pntNTHqDr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized = df['NEWS_TEXT'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcKgUV0RqZP9",
        "colab_type": "text"
      },
      "source": [
        "### Pad the Reuters News dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UYqUkfVqUWl",
        "colab_type": "text"
      },
      "source": [
        "After tokenization, `tokenized` is a list of sentences that each sentence is represented as a list of tokens. In order to be more efficient and faster, We want BERT to process our examples all at once (as one batch). For that reason, we need to pad all lists to the same size, so we can represent the input as one 2-d array, rather than a list of lists (in different lengths)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkoktj0prl6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huV1DjWAsQMd",
        "colab_type": "text"
      },
      "source": [
        "Our dataset is now in the `padded` variable, we can view its dimensions below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B80QfIVpsQ0_",
        "colab_type": "code",
        "outputId": "c21e5b9a-d5e4-4f09-a973-3a1e72dbc523",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.array(padded).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2165, 86)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLQs1Kc8sf4F",
        "colab_type": "text"
      },
      "source": [
        "### Mask the Reuters News dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJCcwLtQsllH",
        "colab_type": "text"
      },
      "source": [
        "If we directly send `padded` to BERT, that would slightly confuse it. To avoid confusion, We create another variable to tell it to ignore (mask) the padding we've added when it's processing its input. That's what attention_mask is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqIDj7tnsp37",
        "colab_type": "code",
        "outputId": "eaf4cfda-e226-499e-d928-b918806dd262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2165, 86)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQ8nmPbdzZVJ",
        "colab_type": "text"
      },
      "source": [
        "## “Earnings Announcement”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mC4Ony_Ss9eg",
        "colab_type": "text"
      },
      "source": [
        "### DistilBERT Model #1 for Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTKxgIeztKcU",
        "colab_type": "text"
      },
      "source": [
        "Now that we have our model and inputs ready, let's run our model!\n",
        "\n",
        "The `model()` function runs our sentences through BERT. The results of the processing will be returned into `last_hidden_states`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPumgc0etCN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = torch.tensor(padded)  \n",
        "attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2RJYB4FtYTX",
        "colab_type": "text"
      },
      "source": [
        "Let's slice only the part of the output that we need. That is the output corresponding the first token of each sentence. The way BERT does sentence classification, is that it adds a token called `[CLS]` (for classification) at the beginning of every sentence. The output corresponding to that token can be thought of as an embedding for the entire sentence.\n",
        "\n",
        "We'll save those in the `features` variable, as they'll serve as the features to our logitics regression model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH9gtKuXtjyN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = last_hidden_states[0][:,0,:].numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKrTyeorMvw3",
        "colab_type": "code",
        "outputId": "5d18281b-e4f9-4a16-8fab-ee6ef12839b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "features"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.14431146, -0.13774735, -0.07801528, ..., -0.10113572,\n",
              "         0.36493364,  0.17891423],\n",
              "       [-0.21805531, -0.1451973 , -0.01023186, ..., -0.14361796,\n",
              "         0.5414291 , -0.06821286],\n",
              "       [-0.15863766, -0.18726122, -0.02563679, ..., -0.10387485,\n",
              "         0.39985478,  0.43581346],\n",
              "       ...,\n",
              "       [-0.0598238 , -0.00563753,  0.19096635, ..., -0.0381794 ,\n",
              "         0.6116144 ,  0.394104  ],\n",
              "       [-0.09204306, -0.25917462, -0.18157378, ..., -0.0273106 ,\n",
              "         0.34951085,  0.4110036 ],\n",
              "       [-0.1615981 , -0.28920633, -0.08893129, ..., -0.01243179,\n",
              "         0.35322142,  0.48190033]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFX-vZeWtkl0",
        "colab_type": "text"
      },
      "source": [
        "The labels indicating which sentence is positive and negative now go into the `labels` variable, it's the `Earnings Announcement` this time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cejs4s5wttN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = df['EARNINGS']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbP336YcI5PM",
        "colab_type": "code",
        "outputId": "fd9e8142-b274-4133-d076-7e67f2fdbe3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TEST</th>\n",
              "      <th>EARNINGS</th>\n",
              "      <th>ACQUIS</th>\n",
              "      <th>NEWS_TEXT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Mounting trade friction between the U.S. And J...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>survey of provinces and seven cities showed v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Shr .p .p  Div .p .p making .p .p  Turnover . ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Whim Creek Consolidated NL&gt; said the consortiu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>The number of workers employed in the West Ger...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   TEST  EARNINGS  ACQUIS                                          NEWS_TEXT\n",
              "0     1         0       0  Mounting trade friction between the U.S. And J...\n",
              "1     1         0       0   survey of provinces and seven cities showed v...\n",
              "2     1         1       0  Shr .p .p  Div .p .p making .p .p  Turnover . ...\n",
              "3     1         0       1  Whim Creek Consolidated NL> said the consortiu...\n",
              "4     1         0       0  The number of workers employed in the West Ger..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rN8u0leDu3Fh",
        "colab_type": "text"
      },
      "source": [
        "### Logistic Regression Model #1 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkXKWVU_u41v",
        "colab_type": "text"
      },
      "source": [
        "apply the embeddings from the\n",
        "trained Model #1 based on the Reuters News dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5iLEUlAzDbM",
        "colab_type": "text"
      },
      "source": [
        "#### Random train/test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hf46PjtswW75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GR8837s9K44F",
        "colab_type": "text"
      },
      "source": [
        "After split our test and training dataset, we fit our logistic regression model by trainning dataset with its features and labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiYeA98Hwz1Y",
        "colab_type": "code",
        "outputId": "24693ffb-4ee1-442a-acaf-2e1b4938c288",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "lr_clf = LogisticRegression()\n",
        "lr_clf.fit(train_features, train_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enDnDkqGztIe",
        "colab_type": "text"
      },
      "source": [
        "#### Evaluate the Performance of the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gnKc22t0BM8",
        "colab_type": "text"
      },
      "source": [
        "Determine the prediction accuracy for the testing sample.  \n",
        "\n",
        "check the accuracy against the testing dataset for how welL our model does in classifying sentences:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PWxHtmVw4ek",
        "colab_type": "code",
        "outputId": "af24a3bd-dbbf-428b-939d-8b83f0650664",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lr_clf.score(test_features, test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9538745387453874"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-MOqU6QLUMS",
        "colab_type": "text"
      },
      "source": [
        "Our model is 95.4% correct for classifying sentences.\n",
        "\n",
        "Also, we take a look at the dummy classifier to evaluate our accuracy score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZIkl0pBLUjm",
        "colab_type": "code",
        "outputId": "ffc76e1f-9128-4f19-b8b1-38b15f1f857b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "clf = DummyClassifier()\n",
        "\n",
        "scores = cross_val_score(clf, train_features, train_labels)\n",
        "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dummy classifier score: 0.746 (+/- 0.04)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_m6J6Ir1Ldi9",
        "colab_type": "text"
      },
      "source": [
        "Obviously, since our model has the accuracy score of 0.954, which is much higher than dummy classifier score with 0.746, our model did a good job for prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTCMofwVnMgm",
        "colab_type": "text"
      },
      "source": [
        "### Logistic Regression Model #1 Cont."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIVDeN3k3qy_",
        "colab_type": "text"
      },
      "source": [
        "#### Use the actual training/test variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5HQCmYhLo7e",
        "colab_type": "text"
      },
      "source": [
        "First, we create a copy of our original dataframe in order to process the utilization of actual training/test variable. Then, we attached `features` that we created before to our dataframe as a new column named `features`for modeling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxwSZ4tmBzWw",
        "colab_type": "code",
        "outputId": "cf575bf6-6346-47d8-9f31-113c7c820648",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df2=df.copy()\n",
        "df2['features'] = features.tolist()\n",
        "df2.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TEST</th>\n",
              "      <th>EARNINGS</th>\n",
              "      <th>ACQUIS</th>\n",
              "      <th>NEWS_TEXT</th>\n",
              "      <th>features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Mounting trade friction between the U.S. And J...</td>\n",
              "      <td>[-0.14431145787239075, -0.13774734735488892, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>survey of provinces and seven cities showed v...</td>\n",
              "      <td>[-0.21805530786514282, -0.1451973021030426, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Shr .p .p  Div .p .p making .p .p  Turnover . ...</td>\n",
              "      <td>[-0.1586376577615738, -0.18726122379302979, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Whim Creek Consolidated NL&gt; said the consortiu...</td>\n",
              "      <td>[0.06605631858110428, -0.12267395853996277, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>The number of workers employed in the West Ger...</td>\n",
              "      <td>[-0.15836602449417114, -0.016903648152947426, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   TEST  ...                                           features\n",
              "0     1  ...  [-0.14431145787239075, -0.13774734735488892, -...\n",
              "1     1  ...  [-0.21805530786514282, -0.1451973021030426, -0...\n",
              "2     1  ...  [-0.1586376577615738, -0.18726122379302979, -0...\n",
              "3     1  ...  [0.06605631858110428, -0.12267395853996277, -0...\n",
              "4     1  ...  [-0.15836602449417114, -0.016903648152947426, ...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYqf8xWdZrJg",
        "colab_type": "text"
      },
      "source": [
        "Then we split test and training dataset according to `TEST` variable, which means that we will utilize the actual training and test split of data frame to train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65K2BWooB_93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split features and labels based on the 'TEST' variable in df\n",
        "train_features2=df2.features[df2['TEST'] == 0]\n",
        "test_features2=df2.features[df2['TEST'] == 1]\n",
        "train_labels2=df2.EARNINGS[df2['TEST'] == 0]\n",
        "test_labels2=df2.EARNINGS[df2['TEST'] == 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nsEgykOaJ9G",
        "colab_type": "text"
      },
      "source": [
        "By checking the types of labels and features that we generated above, we know that the data types are not the same as the data type that logistic regression model requires. Therefore, we transform the data format into numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpQqzF_BSz8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#transfer to correct format\n",
        "train_features3 = np.array([np.array(xi) for xi in train_features2])\n",
        "test_features3 = np.array([np.array(xi) for xi in test_features2])\n",
        "train_labels3 = train_labels2\n",
        "test_labels3 = test_labels2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SXAZdLya2lr",
        "colab_type": "text"
      },
      "source": [
        "Last, we run our logistic regression model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "948Z5ILhDJE4",
        "colab_type": "code",
        "outputId": "e7c0d63e-6efb-4718-9492-f0fc732d87e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "lr_clf2 = LogisticRegression()\n",
        "lr_clf2.fit(train_features3, train_labels3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-TxamKfpDY5W"
      },
      "source": [
        "#### Evaluate the Performance of the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f4bmHMyqDY5Y"
      },
      "source": [
        "Determine the prediction accuracy for the testing sample.  \n",
        "\n",
        "Check the accuracy against the actual testing dataset for how well our model does in classifying sentences:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f9e0db2a-ac21-4296-a3c9-718a1e91bc7f",
        "id": "IaLV60lVDY5Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lr_clf2.score(test_features3, test_labels3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9772329246935202"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P867ybRehlVi",
        "colab_type": "text"
      },
      "source": [
        "Our model is about 97.7% correct for predicting `EARNINGS` variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ0WlNGEbJGI",
        "colab_type": "code",
        "outputId": "d77d03c8-0713-4ecb-d62f-cbe749fae631",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "clf2 = DummyClassifier()\n",
        "\n",
        "scores2 = cross_val_score(clf2, train_features3, train_labels3)\n",
        "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores2.mean(), scores2.std() * 2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dummy classifier score: 0.715 (+/- 0.02)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5Ia6mI1a87S",
        "colab_type": "text"
      },
      "source": [
        "By creating a dummy classifier, we check the performance of our accuracy scores. Obviously, since our model has the accuracy score of around 0.977, which is much higher than dummy classifier score, our model did a good job for predicting `EARNINGS` variable.\n",
        "\n",
        "**Moreover**, the model that we trained by actual train/test split has **higher** accuracy scores (0.977) than random train/test split (0.954). Such situation indicates that different methods of splitting training and test dataset will influence the performance of the model distinctively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWiRgwA208Pi",
        "colab_type": "text"
      },
      "source": [
        "## “Corporate Acquisition”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LKUDqzCC1MgO"
      },
      "source": [
        "### DistilBERT Model #1 for Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkSj0oiX2CU5",
        "colab_type": "text"
      },
      "source": [
        "We have our model and features above, and they are same here, so we don't need to rebuild the model and features this time, we only need to change labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mWV4Vrxf1Mgd"
      },
      "source": [
        "The labels indicating which sentence is positive and negative now go into the `labels` variable, it's the `Corporate Acquisition` this time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dXB4MSMj1Mge",
        "colab": {}
      },
      "source": [
        "labels = df['ACQUIS']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ql53d2Ao1Mgh"
      },
      "source": [
        "### Logistic Regression Model #1 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aDliNj6X1Mgi"
      },
      "source": [
        "apply the embeddings from the\n",
        "trained Model #1 based on the Reuters News dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uZRie7dT1Mgj"
      },
      "source": [
        "#### Random train/test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C2f2wCse1Mgk",
        "colab": {}
      },
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d59ba9a2-1cc9-43b4-a0e0-89a9cd4377fa",
        "id": "JwjrPJ1G1Mgo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "lr_clf = LogisticRegression()\n",
        "lr_clf.fit(train_features, train_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R0ZBCvJAOBgo"
      },
      "source": [
        "#### Evaluate the Performance of the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RJs3JZy9OBgp"
      },
      "source": [
        "Determine the prediction accuracy for the testing sample.  \n",
        "\n",
        "Check the accuracy against the random testing dataset for how well our model does in classifying sentences:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e45ffd7d-f8bc-449f-ee6c-4bfb5845009c",
        "id": "g3e0bHbkOBgq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lr_clf.score(test_features, test_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9428044280442804"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ser24zhzh8G7",
        "colab_type": "text"
      },
      "source": [
        "Our model is 94.3% correct when predicts `ACQUIS` variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w02vrtLyb8cf",
        "colab_type": "code",
        "outputId": "e9d4215c-c1de-4998-cfce-b8e3b95f20fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "clf = DummyClassifier()\n",
        "\n",
        "scores = cross_val_score(clf, train_features, train_labels)\n",
        "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dummy classifier score: 0.531 (+/- 0.02)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRTRIOkvcAkD",
        "colab_type": "text"
      },
      "source": [
        "The accuracy of our model for predicting `ACQUIS` variable is around 0.943. Also, we built a dummy classifier with a value of 0.531. Obviously, our model does a good job on predicting `ACQUIS` variable. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8fqJaPGnhSV",
        "colab_type": "text"
      },
      "source": [
        "### Logistic Regression Model #1 Cont."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oi0lEkqTOBgw"
      },
      "source": [
        "#### Use the actual training/test variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6MeIEpscNLO",
        "colab_type": "text"
      },
      "source": [
        "Similarily, we also utilize the actual trainig/test variable to train our model which predicts `AQUIS` variable. The steps are the same as the model of predicting `EARNINGS` variable using actual training/test variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "96KAo9RJVVEh",
        "colab": {}
      },
      "source": [
        "# split features and labels based on the 'TEST' variable in df\n",
        "train_features4=df2.features[df2['TEST'] == 0]\n",
        "test_features4=df2.features[df2['TEST'] == 1]\n",
        "train_labels4=df2.ACQUIS[df2['TEST'] == 0]\n",
        "test_labels4=df2.ACQUIS[df2['TEST'] == 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_UWW73E1VVEk",
        "colab": {}
      },
      "source": [
        "#transfer to correct format\n",
        "train_features5 = np.array([np.array(xi) for xi in train_features4])\n",
        "test_features5 = np.array([np.array(xi) for xi in test_features4])\n",
        "train_labels5 = train_labels4\n",
        "test_labels5 = test_labels4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "58a5790e-27c4-49f5-adfd-662ed532e90c",
        "id": "JJKU4CElVVEm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "lr_clf2 = LogisticRegression()\n",
        "lr_clf2.fit(train_features5, train_labels5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GyddjzdcVVEo"
      },
      "source": [
        "#### Evaluate the Performance of the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PFFSbogeVVEp"
      },
      "source": [
        "Determine the prediction accuracy for the testing sample.  \n",
        "\n",
        "To check the accuracy against the testing dataset for how well does our model do in classifying sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b26c7d5a-fadb-4eb7-91b8-b1a570b46752",
        "id": "AZyR1YxCVVEp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lr_clf2.score(test_features5, test_labels5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9492119089316988"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOAcqUWQiJM1",
        "colab_type": "text"
      },
      "source": [
        "Our model is 94.9% correct for predicting `AQUIS` variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIxjtOnPcaPx",
        "colab_type": "code",
        "outputId": "4e3c15b3-5fce-47ad-c4d5-53c4770ef091",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "clf3 = DummyClassifier()\n",
        "\n",
        "scores3 = cross_val_score(clf3, train_features5, train_labels5)\n",
        "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores3.mean(), scores3.std() * 2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dummy classifier score: 0.556 (+/- 0.06)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RESLRovEcl_z",
        "colab_type": "text"
      },
      "source": [
        "The accuracy of our model for predicting `ACQUIS` variable is around 0.949. Also, we built a dummy classifier with a value of 0.556. Obviously, our model does a good job on predicting `ACQUIS` variable. \n",
        "\n",
        "Though the results of accuracy scores are still slightly different (0.943 for random split vs. 0.949 for actual split) by using different methods of training/test split, the scale of such difference is very small (less than 0.01). Therefore, we do not think two different ways we utilized in this homework to select test/train split are significant enough to be considered into further analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcAG5JLHftzG",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate Performance for Different Variables and Different Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCYMHI74inb4",
        "colab_type": "text"
      },
      "source": [
        "Overall, logistic regression model that we built works better for predicting the `EARNINGS` variable than the `ACQUIS` variable, since the accuracy scores of `EARNINGS` by both random split and actual split are higher than those of `ACQUIS` variable. Actual Split works better for Random Split in this sample in our BERT model. Both our models clearly do better than dummy classifiers. Nevertheless, to further compare two set of models with two variables, we might need to consider more methods of model evaluations, such as AUC scores, in the future. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKKw-YkLr6ms",
        "colab_type": "text"
      },
      "source": [
        "# Naïve Bayes estimation method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABUnrxiutAwJ",
        "colab_type": "text"
      },
      "source": [
        "## Install the nltk library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RD0WQpy4wNsF",
        "outputId": "9d76d2b9-f1c7-49af-9274-8bbdb38234c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('all')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdwMBKZZEJ_E",
        "colab_type": "text"
      },
      "source": [
        "## Get a Wordlist for Reuters News"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GdAiSDycwR0e",
        "colab": {}
      },
      "source": [
        "df_NB=df.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_3VvUeL0tFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create wordlist\n",
        "word_NB = []\n",
        "for m in range(0, len(df_NB)):\n",
        "  i=df_NB.iloc[m].NEWS_TEXT.split()\n",
        "  for n in i:\n",
        "    word_NB.append(n)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJjD3vx3QjN5",
        "colab_type": "code",
        "outputId": "39d24b7c-f40e-42c7-ebc0-a48dd27ba583",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#check the list with first 10 words\n",
        "word_NB[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mounting',\n",
              " 'trade',\n",
              " 'friction',\n",
              " 'between',\n",
              " 'the',\n",
              " 'U.S.',\n",
              " 'And',\n",
              " 'Japan',\n",
              " 'has',\n",
              " 'raised']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdVx_-jX9GbQ",
        "colab_type": "text"
      },
      "source": [
        "## Remove the Punctuations and Stop Words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO2-vzZm5PwB",
        "colab_type": "text"
      },
      "source": [
        "We found that there are punctuations and stop words in our word tokens, which are useless for our prediction. \n",
        "\n",
        "So we remove the punctuations and stop words. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0KkTA3i48cE",
        "colab_type": "code",
        "outputId": "db78aaef-a3d6-472d-9955-c7bf7852513f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "## remove punctuations and stop words\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "word_NB = [w.lower() for w in word_NB]\n",
        "table = str.maketrans('', '', string.punctuation)\n",
        "stripped = [w.translate(table) for w in word_NB]\n",
        "stop_words = set(stopwords.words('english'))\n",
        "words = [w for w in stripped if not w in stop_words]\n",
        "words[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mounting',\n",
              " 'trade',\n",
              " 'friction',\n",
              " 'us',\n",
              " 'japan',\n",
              " 'raised',\n",
              " 'fears',\n",
              " 'among',\n",
              " 'many',\n",
              " 'asias']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfWReaPiDDWL",
        "colab_type": "text"
      },
      "source": [
        "## Create a frequency count of words in each Reuters News"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLIda5yx0gBH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the feature extractor\n",
        "NB_words = nltk.FreqDist(w.lower() for w in words)\n",
        "\n",
        "def document_features(document):\n",
        "    document_words = set(document)\n",
        "    features = {}\n",
        "    for word in NB_words:\n",
        "        features['contains({})'.format(word)] = (word in document_words)\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60MdMcQxSzPT",
        "colab_type": "text"
      },
      "source": [
        "## Data Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M69FDp8cUu8p",
        "colab_type": "text"
      },
      "source": [
        "### Random Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw0Z5qRZ7Ka-",
        "colab_type": "text"
      },
      "source": [
        "We randomly assign data to test and training data set by 25% vs. 75% split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdmS9HC-YxjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#a random 75% training and 25% Testing Split\n",
        "train = df_NB.sample(frac=0.75, random_state=6)\n",
        "test = df_NB.loc[~df_NB.index.isin(train.index), :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlIT1uSIZMUU",
        "colab_type": "code",
        "outputId": "9b2ce1f0-4582-4597-9602-ed1dbc1f8ff9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(len(train))\n",
        "print(len(test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1624\n",
            "541\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgq5vQw9SjK3",
        "colab_type": "text"
      },
      "source": [
        "### Actual Split based on `TEST` varaible"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bq8fvzGU7VEN",
        "colab_type": "text"
      },
      "source": [
        "We also assign data according to `TEST` variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2C7QK0Awcni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_NB = df_NB[df_NB.TEST == 1]\n",
        "train_NB = df_NB[df_NB.TEST == 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snPvsbDvZlkQ",
        "colab_type": "code",
        "outputId": "1456de7b-7b17-4fdc-aade-4056b65f090f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(len(train_NB))\n",
        "print(len(test_NB))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1594\n",
            "571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkFNFdTeCZUD",
        "colab_type": "text"
      },
      "source": [
        "## “Earnings Announcement”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJAfcSgQaTl7",
        "colab_type": "text"
      },
      "source": [
        "### Random Check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoTQB1iObkhs",
        "colab_type": "text"
      },
      "source": [
        "#### Train Naïve Bayes Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZVZwxn-waz0u",
        "colab": {}
      },
      "source": [
        "#extract 'earnings'\n",
        "Earnings_NB_train=train.EARNINGS\n",
        "Earnings_NB_test=test.EARNINGS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HGqoU8KDaz0x",
        "colab": {}
      },
      "source": [
        "# create train dataset -- earnings\n",
        "train_earnings = [(list(train.iloc[i].NEWS_TEXT.split()), Earnings_NB_train.iloc[i])\n",
        "                            for i in range(0, len(train))]\n",
        "test_earnings = [(list(test.iloc[i].NEWS_TEXT.split()), Earnings_NB_test.iloc[i])\n",
        "                            for i in range(0, len(test))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BLXSI5dFaz0z",
        "colab": {}
      },
      "source": [
        "#train NB model -- earnings\n",
        "featuresets_train_earnings = [(document_features(m), n) for (m,n) in train_earnings]\n",
        "featuresets_test_earnings = [(document_features(m), n) for (m,n) in test_earnings]\n",
        "classifier_earnings= nltk.NaiveBayesClassifier.train(featuresets_train_earnings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HMxbpcbGaz01"
      },
      "source": [
        "#### Evaluate the Performance of the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "03623564-438a-4426-c3c8-0f35df35b715",
        "id": "B5qiQ5Diaz01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# accuracy on test dataset -- earnings\n",
        "accuracy=nltk.classify.accuracy(classifier_earnings, featuresets_test_earnings)\n",
        "accuracy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.966728280961183"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubi3YKZXfBoR",
        "colab_type": "text"
      },
      "source": [
        "The accuracy of our model for predicting `EARNINGS` variable is around 0.967. Obviously, our model does a good job on predicting `EARNINGS` variable. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw_JOeOqatRl",
        "colab_type": "text"
      },
      "source": [
        "### Actual Check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDqE6vXXb1sM",
        "colab_type": "text"
      },
      "source": [
        "#### Train Naïve Bayes Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGIXJP9x10sz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#extract 'earnings'\n",
        "Earnings_NB_train=train_NB.EARNINGS\n",
        "Earnings_NB_test=test_NB.EARNINGS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXxq_pK72PvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create train dataset -- earnings\n",
        "train_earnings = [(list(train_NB.iloc[i].NEWS_TEXT.split()), Earnings_NB_train.iloc[i])\n",
        "                            for i in range(0, len(train_NB))]\n",
        "test_earnings = [(list(test_NB.iloc[i].NEWS_TEXT.split()), Earnings_NB_test.iloc[i])\n",
        "                            for i in range(0, len(test_NB))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMzO6iKD68PV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train NB model -- earnings\n",
        "featuresets_train_earnings = [(document_features(m), n) for (m,n) in train_earnings]\n",
        "featuresets_test_earnings = [(document_features(m), n) for (m,n) in test_earnings]\n",
        "classifier_earnings= nltk.NaiveBayesClassifier.train(featuresets_train_earnings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyGO8Y_BDrKz",
        "colab_type": "text"
      },
      "source": [
        "#### Evaluate the Performance of the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjVL1Epl81pW",
        "colab_type": "code",
        "outputId": "26d6845a-c7cc-4521-9016-51d7499b3dd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# accuracy on test dataset -- earnings\n",
        "accuracy=nltk.classify.accuracy(classifier_earnings, featuresets_test_earnings)\n",
        "accuracy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9527145359019265"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa_NoqLqfesV",
        "colab_type": "text"
      },
      "source": [
        "The accuracy of our model for predicting `EARNINGS` variable is around 0.953. Obviously, our model does a good job on predicting `EARNINGS` variable. \n",
        "\n",
        "Though the results of accuracy scores are still slightly different (0.967 for random split vs. 0.953 for actual split) by using different methods of training/test split, the scale of such difference is very small (less than 0.02). Therefore, we do not think two different ways we utilized in this homework to select test/train split are significant enough to be considered into further analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0ZdFFB0kCZ-",
        "colab_type": "code",
        "outputId": "22c0de38-80c1-494b-91bd-74a29219f3d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# Show the most important features as interpreted by Naive Bayes in EARNINGS\n",
        "classifier_earnings.show_most_informative_features(20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most Informative Features\n",
            "      contains(dividend) = True                1 : 0      =     96.4 : 1.0\n",
            "     contains(quarterly) = True                1 : 0      =     76.3 : 1.0\n",
            "      contains(earnings) = True                1 : 0      =     65.9 : 1.0\n",
            "       contains(profits) = True                1 : 0      =     57.4 : 1.0\n",
            "     contains(reporting) = True                1 : 0      =     53.5 : 1.0\n",
            "        contains(profit) = True                1 : 0      =     47.1 : 1.0\n",
            "       contains(payable) = True                1 : 0      =     35.5 : 1.0\n",
            "      contains(declared) = True                1 : 0      =     27.6 : 1.0\n",
            "        contains(income) = True                1 : 0      =     27.1 : 1.0\n",
            "   contains(improvement) = True                1 : 0      =     24.3 : 1.0\n",
            "        contains(losses) = True                1 : 0      =     24.3 : 1.0\n",
            "       contains(results) = True                1 : 0      =     21.7 : 1.0\n",
            "        contains(fourth) = True                1 : 0      =     21.1 : 1.0\n",
            "           contains(net) = True                1 : 0      =     21.1 : 1.0\n",
            "          contains(loss) = True                1 : 0      =     20.3 : 1.0\n",
            "       contains(holders) = True                1 : 0      =     18.8 : 1.0\n",
            "        contains(pretax) = True                1 : 0      =     17.8 : 1.0\n",
            "       contains(expects) = True                1 : 0      =     16.5 : 1.0\n",
            "       contains(quarter) = True                1 : 0      =     14.8 : 1.0\n",
            "     contains(operating) = True                1 : 0      =     14.6 : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM3BNmVsCSIQ",
        "colab_type": "text"
      },
      "source": [
        "## “Corporate Acquisition”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n-wgz2wCb6zn"
      },
      "source": [
        "### Random Check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3eaTmDnzb6zo"
      },
      "source": [
        "#### Train Naïve Bayes Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SBQX3C-pcIes",
        "colab": {}
      },
      "source": [
        "#extract 'acquis'\n",
        "ACQUIS_NB_train=train.ACQUIS\n",
        "ACQUIS_NB_test=test.ACQUIS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ss26qO_wcIey",
        "colab": {}
      },
      "source": [
        "# create train dataset -- acquis\n",
        "train_acquis = [(list(train.iloc[i].NEWS_TEXT.split()), ACQUIS_NB_train.iloc[i])\n",
        "                            for i in range(0, len(train))]\n",
        "test_acquis = [(list(test.iloc[i].NEWS_TEXT.split()), ACQUIS_NB_test.iloc[i])\n",
        "                            for i in range(0, len(test))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pw72eskBcIe5",
        "colab": {}
      },
      "source": [
        "#train NB model -- acquis\n",
        "featuresets_train_acquis = [(document_features(a), b) for (a,b) in train_acquis]\n",
        "featuresets_test_acquis = [(document_features(a), b) for (a,b) in test_acquis]\n",
        "classifier_acquis= nltk.NaiveBayesClassifier.train(featuresets_train_acquis)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oDCTqgg8cIfQ"
      },
      "source": [
        "#### Evaluate the Performance of the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9df84973-e00f-4e76-9029-7593720be4b4",
        "id": "TPRonYP9cIfR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# accuracy on test dataset -- acquis\n",
        "accuracy=nltk.classify.accuracy(classifier_acquis, featuresets_test_acquis)\n",
        "accuracy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9390018484288355"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjFFKkGffFqB",
        "colab_type": "text"
      },
      "source": [
        "The accuracy of our model for predicting `ACQUIS` variable is around 0.939. Obviously, our model does a good job on predicting `ACQUIS` variable. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tCGuY0WpcAZi"
      },
      "source": [
        "### Actual Check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gmvdjQGOcAZj"
      },
      "source": [
        "#### Train Naïve Bayes Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx7jYEQm3dkR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#extract 'acquis'\n",
        "ACQUIS_NB_train=train_NB.ACQUIS\n",
        "ACQUIS_NB_test=test_NB.ACQUIS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5qOGsmQ3fLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create train dataset -- acquis\n",
        "train_acquis = [(list(train_NB.iloc[i].NEWS_TEXT.split()), ACQUIS_NB_train.iloc[i])\n",
        "                            for i in range(0, len(train_NB))]\n",
        "test_acquis = [(list(test_NB.iloc[i].NEWS_TEXT.split()), ACQUIS_NB_test.iloc[i])\n",
        "                            for i in range(0, len(test_NB))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hcgobz3v9xTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train NB model -- acquis\n",
        "featuresets_train_acquis = [(document_features(a), b) for (a,b) in train_acquis]\n",
        "featuresets_test_acquis = [(document_features(a), b) for (a,b) in test_acquis]\n",
        "classifier_acquis= nltk.NaiveBayesClassifier.train(featuresets_train_acquis)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhPTHTYHDpEe",
        "colab_type": "text"
      },
      "source": [
        "#### Evaluate the Performance of the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Fx2YAL2-AOm",
        "colab_type": "code",
        "outputId": "5dd30210-116d-4496-9039-d36663c3385d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# accuracy on test dataset -- acquis\n",
        "accuracy=nltk.classify.accuracy(classifier_acquis, featuresets_test_acquis)\n",
        "accuracy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9369527145359019"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I77XwAAZeI09",
        "colab_type": "text"
      },
      "source": [
        "The accuracy of our model for predicting `ACQUIS` variable is around 0.937. Obviously, our model does a good job on predicting `ACQUIS` variable. \n",
        "\n",
        "Though the results of accuracy scores are still slightly different (0.939 for random split vs. 0.937 for actual split) by using different methods of training/test split, the scale of such difference is very small (less than 0.01). Therefore, we do not think two different ways we utilized in this homework to select test/train split are significant enough to be considered into further analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJNEkHEPj0Ni",
        "colab_type": "code",
        "outputId": "e8e25053-e1b1-47a6-a287-bdec0fde543b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# Show the most important features as interpreted by Naive Bayes in ACQUIS\n",
        "classifier_acquis.show_most_informative_features(20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most Informative Features\n",
            "       contains(acquire) = True                1 : 0      =     88.0 : 1.0\n",
            "        contains(intent) = True                1 : 0      =     37.7 : 1.0\n",
            "        contains(merger) = True                1 : 0      =     37.0 : 1.0\n",
            "          contains(rate) = True                0 : 1      =     26.6 : 1.0\n",
            "        contains(filing) = True                1 : 0      =     26.2 : 1.0\n",
            "         contains(stake) = True                1 : 0      =     26.1 : 1.0\n",
            "      contains(investor) = True                1 : 0      =     24.1 : 1.0\n",
            "        contains(prices) = True                0 : 1      =     24.0 : 1.0\n",
            "      contains(takeover) = True                1 : 0      =     22.6 : 1.0\n",
            "      contains(acquired) = True                1 : 0      =     21.4 : 1.0\n",
            "          contains(fell) = True                0 : 1      =     21.4 : 1.0\n",
            "          contains(rise) = True                0 : 1      =     20.6 : 1.0\n",
            "        contains(letter) = True                1 : 0      =     19.2 : 1.0\n",
            "         contains(merge) = True                1 : 0      =     17.4 : 1.0\n",
            "         contains(money) = True                0 : 1      =     16.9 : 1.0\n",
            "   contains(considering) = True                1 : 0      =     16.2 : 1.0\n",
            "   contains(acquisition) = True                1 : 0      =     15.9 : 1.0\n",
            "   contains(transaction) = True                1 : 0      =     14.7 : 1.0\n",
            "          contains(rose) = True                0 : 1      =     14.1 : 1.0\n",
            "         contains(trade) = True                0 : 1      =     13.6 : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_eSSksKmf0QV"
      },
      "source": [
        "## Evaluate Performance for Different Variables and Different Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wdU_gcMof0QW"
      },
      "source": [
        "For the `Naïve Bayes` model, both random split works better for actual split in our sample. The `Naïve Bayes` model that we built works better for predicting the `EARNINGS` variable than the `ACQUIS` variable, since the accuracy scores of `EARNINGS` by both random split and actual split are higher than those of `ACQUIS` variable. Thus, overall, both `BERT` model and `Naïve Bayes` model work better for predicting the `EARNINGS` variable than the `ACQUIS` variable.  \n",
        "\n",
        "For predicting the `EARNINGS` variable, the `Naïve Bayes` model that we built works better than the `BERT` model for the random split method, and the `BERT` model that we built works better than the `Naïve Bayes` model for the actual split method.  \n",
        "\n",
        "For predicting the `ACQUIS` variable, the `Naïve Bayes` model that we built works better than the `BERT` model for both data split methods.   \n",
        "\n",
        "Thus, different dataset may have different accuracy results for different models, we can not say which one is better. However, in this Reuters News dataset, predicting the `EARNINGS` variable works better than the `ACQUIS` variable.    "
      ]
    }
  ]
}